{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR_10_Keras(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RJ-ze9tOGMf",
        "colab_type": "code",
        "outputId": "bf13e175-73d7-45f4-8cec-0b5067e72109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "batch_size = 200\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "#data_augmentation = True\n",
        "num_predictions = 20\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(256, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test, y_test),shuffle=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 32s 637us/step - loss: 2.0207 - acc: 0.2395 - val_loss: 1.5364 - val_acc: 0.4334\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 22s 450us/step - loss: 1.4535 - acc: 0.4650 - val_loss: 1.2504 - val_acc: 0.5524\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 23s 450us/step - loss: 1.1813 - acc: 0.5753 - val_loss: 1.0704 - val_acc: 0.6159\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 1.0115 - acc: 0.6415 - val_loss: 0.8929 - val_acc: 0.6844\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.8916 - acc: 0.6863 - val_loss: 0.8167 - val_acc: 0.7080\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.7941 - acc: 0.7218 - val_loss: 0.7595 - val_acc: 0.7339\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.7208 - acc: 0.7476 - val_loss: 0.7409 - val_acc: 0.7416\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.6657 - acc: 0.7659 - val_loss: 0.6701 - val_acc: 0.7719\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 23s 450us/step - loss: 0.6187 - acc: 0.7827 - val_loss: 0.6612 - val_acc: 0.7726\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.5780 - acc: 0.7963 - val_loss: 0.6434 - val_acc: 0.7813\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.5364 - acc: 0.8123 - val_loss: 0.6281 - val_acc: 0.7864\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.5047 - acc: 0.8232 - val_loss: 0.6137 - val_acc: 0.7921\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.4776 - acc: 0.8338 - val_loss: 0.6298 - val_acc: 0.7909\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.4559 - acc: 0.8395 - val_loss: 0.6034 - val_acc: 0.8028\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.4462 - acc: 0.8431 - val_loss: 0.5636 - val_acc: 0.8144\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.4142 - acc: 0.8554 - val_loss: 0.5982 - val_acc: 0.8084\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.4012 - acc: 0.8602 - val_loss: 0.5614 - val_acc: 0.8170\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.3792 - acc: 0.8663 - val_loss: 0.5579 - val_acc: 0.8193\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.3641 - acc: 0.8731 - val_loss: 0.6044 - val_acc: 0.8115\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.3540 - acc: 0.8755 - val_loss: 0.5661 - val_acc: 0.8216\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.3446 - acc: 0.8792 - val_loss: 0.5586 - val_acc: 0.8244\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.3318 - acc: 0.8834 - val_loss: 0.5737 - val_acc: 0.8204\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.3116 - acc: 0.8881 - val_loss: 0.5762 - val_acc: 0.8247\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.3071 - acc: 0.8909 - val_loss: 0.5749 - val_acc: 0.8270\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.2989 - acc: 0.8952 - val_loss: 0.5855 - val_acc: 0.8200\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2863 - acc: 0.9003 - val_loss: 0.6204 - val_acc: 0.8140\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2781 - acc: 0.9017 - val_loss: 0.5821 - val_acc: 0.8220\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2726 - acc: 0.9049 - val_loss: 0.5952 - val_acc: 0.8223\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2653 - acc: 0.9072 - val_loss: 0.6120 - val_acc: 0.8257\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 22s 450us/step - loss: 0.2647 - acc: 0.9049 - val_loss: 0.6027 - val_acc: 0.8253\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2557 - acc: 0.9114 - val_loss: 0.6007 - val_acc: 0.8268\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 23s 451us/step - loss: 0.2493 - acc: 0.9130 - val_loss: 0.6323 - val_acc: 0.8165\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 22s 450us/step - loss: 0.2440 - acc: 0.9157 - val_loss: 0.6363 - val_acc: 0.8196\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.2369 - acc: 0.9174 - val_loss: 0.5813 - val_acc: 0.8289\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2342 - acc: 0.9179 - val_loss: 0.5959 - val_acc: 0.8333\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.2329 - acc: 0.9199 - val_loss: 0.6259 - val_acc: 0.8246\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.2190 - acc: 0.9241 - val_loss: 0.6234 - val_acc: 0.8292\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2218 - acc: 0.9230 - val_loss: 0.6282 - val_acc: 0.8235\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.2147 - acc: 0.9261 - val_loss: 0.6367 - val_acc: 0.8271\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.2098 - acc: 0.9277 - val_loss: 0.6277 - val_acc: 0.8298\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.2079 - acc: 0.9264 - val_loss: 0.6380 - val_acc: 0.8291\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.2034 - acc: 0.9303 - val_loss: 0.6153 - val_acc: 0.8333\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.2022 - acc: 0.9303 - val_loss: 0.6134 - val_acc: 0.8322\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1972 - acc: 0.9322 - val_loss: 0.6526 - val_acc: 0.8313\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1897 - acc: 0.9355 - val_loss: 0.6701 - val_acc: 0.8256\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1923 - acc: 0.9330 - val_loss: 0.6280 - val_acc: 0.8332\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.1893 - acc: 0.9345 - val_loss: 0.6686 - val_acc: 0.8274\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1901 - acc: 0.9346 - val_loss: 0.6727 - val_acc: 0.8264\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1821 - acc: 0.9373 - val_loss: 0.6708 - val_acc: 0.8277\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1852 - acc: 0.9371 - val_loss: 0.6428 - val_acc: 0.8251\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1860 - acc: 0.9381 - val_loss: 0.6408 - val_acc: 0.8357\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1756 - acc: 0.9396 - val_loss: 0.6917 - val_acc: 0.8293\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1757 - acc: 0.9401 - val_loss: 0.6427 - val_acc: 0.8322\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1717 - acc: 0.9415 - val_loss: 0.7062 - val_acc: 0.8266\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1688 - acc: 0.9431 - val_loss: 0.6761 - val_acc: 0.8354\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1702 - acc: 0.9423 - val_loss: 0.6742 - val_acc: 0.8321\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1676 - acc: 0.9433 - val_loss: 0.7135 - val_acc: 0.8296\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1622 - acc: 0.9450 - val_loss: 0.6742 - val_acc: 0.8284\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1687 - acc: 0.9424 - val_loss: 0.7000 - val_acc: 0.8256\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1619 - acc: 0.9456 - val_loss: 0.6812 - val_acc: 0.8329\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1568 - acc: 0.9472 - val_loss: 0.7418 - val_acc: 0.8253\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1533 - acc: 0.9490 - val_loss: 0.6997 - val_acc: 0.8335\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.1643 - acc: 0.9457 - val_loss: 0.7042 - val_acc: 0.8289\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1613 - acc: 0.9456 - val_loss: 0.6332 - val_acc: 0.8353\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1561 - acc: 0.9489 - val_loss: 0.7169 - val_acc: 0.8243\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1568 - acc: 0.9474 - val_loss: 0.7001 - val_acc: 0.8314\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1497 - acc: 0.9495 - val_loss: 0.7229 - val_acc: 0.8275\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1510 - acc: 0.9492 - val_loss: 0.7150 - val_acc: 0.8315\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.1552 - acc: 0.9479 - val_loss: 0.6943 - val_acc: 0.8347\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1526 - acc: 0.9492 - val_loss: 0.6804 - val_acc: 0.8327\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.1518 - acc: 0.9486 - val_loss: 0.6716 - val_acc: 0.8340\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 22s 449us/step - loss: 0.1482 - acc: 0.9512 - val_loss: 0.7158 - val_acc: 0.8238\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1410 - acc: 0.9538 - val_loss: 0.6858 - val_acc: 0.8331\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1457 - acc: 0.9522 - val_loss: 0.7369 - val_acc: 0.8308\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1372 - acc: 0.9549 - val_loss: 0.6941 - val_acc: 0.8387\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1380 - acc: 0.9539 - val_loss: 0.7217 - val_acc: 0.8333\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.1439 - acc: 0.9518 - val_loss: 0.7154 - val_acc: 0.8304\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1435 - acc: 0.9521 - val_loss: 0.7567 - val_acc: 0.8292\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1434 - acc: 0.9527 - val_loss: 0.6995 - val_acc: 0.8301\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1391 - acc: 0.9546 - val_loss: 0.7273 - val_acc: 0.8265\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1451 - acc: 0.9524 - val_loss: 0.6794 - val_acc: 0.8336\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1357 - acc: 0.9552 - val_loss: 0.6851 - val_acc: 0.8367\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.1310 - acc: 0.9564 - val_loss: 0.7142 - val_acc: 0.8325\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1307 - acc: 0.9577 - val_loss: 0.6858 - val_acc: 0.8377\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1265 - acc: 0.9591 - val_loss: 0.7433 - val_acc: 0.8280\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.1392 - acc: 0.9556 - val_loss: 0.7030 - val_acc: 0.8372\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1366 - acc: 0.9549 - val_loss: 0.7222 - val_acc: 0.8296\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1282 - acc: 0.9581 - val_loss: 0.7377 - val_acc: 0.8332\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.1289 - acc: 0.9572 - val_loss: 0.6976 - val_acc: 0.8330\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.1332 - acc: 0.9564 - val_loss: 0.7038 - val_acc: 0.8356\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1276 - acc: 0.9589 - val_loss: 0.7310 - val_acc: 0.8265\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1363 - acc: 0.9556 - val_loss: 0.7403 - val_acc: 0.8308\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1288 - acc: 0.9574 - val_loss: 0.7436 - val_acc: 0.8279\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1330 - acc: 0.9567 - val_loss: 0.7853 - val_acc: 0.8209\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 22s 447us/step - loss: 0.1345 - acc: 0.9564 - val_loss: 0.7334 - val_acc: 0.8341\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1286 - acc: 0.9589 - val_loss: 0.7363 - val_acc: 0.8311\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1317 - acc: 0.9580 - val_loss: 0.7751 - val_acc: 0.8259\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1307 - acc: 0.9576 - val_loss: 0.7139 - val_acc: 0.8352\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1213 - acc: 0.9602 - val_loss: 0.7594 - val_acc: 0.8358\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 22s 448us/step - loss: 0.1214 - acc: 0.9602 - val_loss: 0.7515 - val_acc: 0.8362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12a2151eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioxGCbNWFJj0",
        "colab_type": "code",
        "outputId": "4168c9af-8bd8-4c78-9b3d-74d0706f46bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 244us/step\n",
            "Test loss: 0.7514999542877078\n",
            "Test accuracy: 0.8362\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}